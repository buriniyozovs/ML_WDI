{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "664e69f4",
   "metadata": {},
   "source": [
    "# 6COSC017C-n, Machine Learning and Data Analytics "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7e8d96",
   "metadata": {},
   "source": [
    "# Importing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9e3e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531eb7b5",
   "metadata": {},
   "source": [
    "# Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7686ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/wdi001.csv\", thousands=',')\n",
    "\n",
    "# Displaying first 5 rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893c318d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset shape\n",
    "print(\"Dataset shape (rows, columns):\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0733e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset info\n",
    "print(\"Dataset info:\", df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630f5a55",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50425128",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Summary statistics:\")\n",
    "display(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa8a7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nMissing values per column:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d3475e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select numeric columns\n",
    "numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "print(\"Numeric columns:\", numeric_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf19bb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot feature distributions for all numeric features\n",
    "features = [col for col in numeric_cols]\n",
    "for feature in features:\n",
    "    plt.figure(figsize=(8,4))\n",
    "    sns.histplot(df[feature], kde=True, bins=50)\n",
    "    plt.title(f'Distribution of {feature}')\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2052744f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect outliers (boxplots) for all numeric columns\n",
    "for col in numeric_cols:\n",
    "    plt.figure(figsize=(8,4))\n",
    "    sns.boxplot(x=df[col])\n",
    "    plt.title(f'Boxplot of {col}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3dafde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute and visualize correlation matrix for numeric columns\n",
    "plt.figure(figsize=(15,12))\n",
    "corr_matrix = df[numeric_cols].corr()\n",
    "sns.heatmap(corr_matrix, annot=True, fmt=\".2f\", cmap='coolwarm')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d687e8",
   "metadata": {},
   "source": [
    "# Data Preparation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8310dd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6ed3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove non-useful categorical columns\n",
    "\n",
    "drop_cat_cols = [\n",
    "    'ISO2 Code',                  # redundant with Country\n",
    "    'Coordinates',                # irregular strings, hard to use,\n",
    "    'Membership',                 # categorical with many levels, not useful for regression\n",
    "    'Regional Group',            # categorical with many levels, not useful for regression\n",
    "]\n",
    "\n",
    "df_clean = df_clean.drop(columns=drop_cat_cols)\n",
    "print(\"Dropped columns:\", drop_cat_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce13d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check missing value percentages\n",
    "missing_percent = df_clean.isnull().mean() * 100\n",
    "missing_percent.sort_values(ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba8dcec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify columns by missing rate\n",
    "# Thresholds: low <5%, moderate 5-60%, high >60%\n",
    "low_missing_cols = missing_percent[missing_percent < 5].index.tolist()\n",
    "moderate_missing_cols = missing_percent[(missing_percent >= 5) & (missing_percent <= 60)].index.tolist()\n",
    "high_missing_cols = missing_percent[missing_percent > 60].index.tolist()\n",
    "\n",
    "print(\"\\nLow missing (<5%) columns:\", low_missing_cols)\n",
    "print(\"Moderate missing (5-50%) columns:\", moderate_missing_cols)\n",
    "print(\"High missing (>50%) columns:\", high_missing_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097cfb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decide targets based on low missing values (less than ~5%) and business relevance\n",
    "low_missing_targets = missing_percent[(missing_percent > 0) & (missing_percent <= 5)].index.tolist()\n",
    "print(\"All moderate-missing columns:\", low_missing_targets)\n",
    "\n",
    "# Choose first 3 columns as main targets\n",
    "target = low_missing_targets[:1]\n",
    "print(\"Selected main target for regression:\", target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9488f2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove extremely high-missing columns\n",
    "\n",
    "drop_hm_cols = [\n",
    "    'Adult Literacy Rate',       # ~92% missing\n",
    "    'Youth Literacy Rate',       # ~91% missing\n",
    "]\n",
    "\n",
    "df_clean = df_clean.drop(columns=drop_hm_cols)\n",
    "print(\"Dropped columns:\", drop_hm_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8167e83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numeric columns\n",
    "numeric_cols = df_clean.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "\n",
    "# Compute and visualize correlation matrix for numeric columns\n",
    "plt.figure(figsize=(15,12))\n",
    "corr_matrix = df[numeric_cols].corr()\n",
    "sns.heatmap(corr_matrix, annot=True, fmt=\".2f\", cmap='coolwarm')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1334cdab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove highly not-correlated columns to the target\n",
    "\n",
    "drop_cols = [\n",
    "    'GDP Growth Rate',\n",
    "    'Labor Force Female',\n",
    "    'Labor Force Male',\n",
    "    'Labor Force Total',\n",
    "    'Unemployment Rate',\n",
    "    'Population Aged 0-14',\n",
    "    'Population Aged 15-64',\n",
    "    'Population Aged 65-up',\n",
    "    'Female Population',\n",
    "    'Male Population',\n",
    "    'Population Total',\n",
    "]\n",
    "\n",
    "df_clean = df_clean.drop(columns=drop_cols)\n",
    "print(\"Dropped columns:\", drop_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2df1706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numeric columns\n",
    "numeric_cols = df_clean.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "\n",
    "# Compute and visualize correlation matrix for numeric columns\n",
    "plt.figure(figsize=(15,12))\n",
    "corr_matrix = df[numeric_cols].corr()\n",
    "sns.heatmap(corr_matrix, annot=True, fmt=\".2f\", cmap='coolwarm')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719f1b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values using median per country\n",
    "for col in numeric_cols:\n",
    "    df_clean[col] = df_clean.groupby('Country')[col].transform(\n",
    "        lambda x: x.fillna(x.median())\n",
    "    )\n",
    "\n",
    "# Fallback global median (rare cases)\n",
    "for col in numeric_cols:\n",
    "    df_clean[col] = df_clean[col].fillna(df_clean[col].median())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de7fc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Select numeric columns\n",
    "numeric_df = df_clean.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "# Step 2: Compute correlation matrix\n",
    "corr_matrix = numeric_df.corr().abs()\n",
    "\n",
    "# Step 3: Compute mean correlation for each possible target\n",
    "mean_corr = corr_matrix.mean().sort_values(ascending=False)\n",
    "\n",
    "# Display ranked list\n",
    "print(\"Mean absolute correlation of each variable:\\n\")\n",
    "print(mean_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1a8aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = [\n",
    "    'Year',\n",
    "    'GDP Total',\n",
    "    'GDP Per Capita',\n",
    "    'Primary School Enrollment',\n",
    "    'Secondary School Enrollment',\n",
    "    'Tertiary School Enrollment'\n",
    "]\n",
    "\n",
    "categorical_features = ['Country']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f71cd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training = df_clean[numeric_features + categorical_features + target].dropna()\n",
    "\n",
    "X = df_training[numeric_features + categorical_features]\n",
    "y = df_training[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4722c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fcff59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREPROCESSING PIPELINE\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), numeric_features),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abb3ad0",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bffd567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL 1 — LINEAR REGRESSION\n",
    "\n",
    "pipe_lr = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocessor),\n",
    "    (\"model\", LinearRegression())\n",
    "])\n",
    "\n",
    "param_lr = {\n",
    "    \"model__fit_intercept\": [True, False],\n",
    "    \"model__positive\": [False],   # explicitly disable positive, removed True when used scaling\n",
    "}\n",
    "\n",
    "\n",
    "grid_lr = GridSearchCV(\n",
    "    estimator=pipe_lr,\n",
    "    param_grid=param_lr,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    cv=3,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_lr.fit(X_train, y_train)\n",
    "best_lr = grid_lr.best_estimator_\n",
    "\n",
    "print(\"Best Linear Regression Params:\", grid_lr.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3119b888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL 2 — RANDOM FOREST\n",
    "\n",
    "pipe_rf = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocessor),\n",
    "    (\"model\", RandomForestRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "param_rf = {\n",
    "    \"model__n_estimators\": [100, 200],\n",
    "    \"model__max_depth\": [5, 10, None],\n",
    "    \"model__min_samples_split\": [2, 5],\n",
    "    \"model__min_samples_leaf\": [1, 2],\n",
    "    \"model__max_features\": [\"sqrt\", \"log2\"],\n",
    "}\n",
    "\n",
    "grid_rf = GridSearchCV(\n",
    "    estimator=pipe_rf,\n",
    "    param_grid=param_rf,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    cv=3,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_rf.fit(X_train, y_train)\n",
    "best_rf = grid_rf.best_estimator_\n",
    "\n",
    "print(\"Best Random Forest Params:\", grid_rf.best_params_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0a9b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL 3 — GRADIENT BOOSTING\n",
    "\n",
    "pipe_gb = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocessor),\n",
    "    (\"model\", GradientBoostingRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "param_gb = {\n",
    "    \"model__n_estimators\": [100, 200],\n",
    "    \"model__learning_rate\": [0.01, 0.05, 0.1],\n",
    "    \"model__max_depth\": [2, 3, 4],\n",
    "    \"model__subsample\": [0.8, 1.0],\n",
    "    \"model__min_samples_split\": [2, 5],\n",
    "    \"model__min_samples_leaf\": [1, 2],\n",
    "}\n",
    "\n",
    "grid_gb = GridSearchCV(\n",
    "    estimator=pipe_gb,\n",
    "    param_grid=param_gb,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    cv=3,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_gb.fit(X_train, y_train)\n",
    "best_gb = grid_gb.best_estimator_\n",
    "\n",
    "print(\"Best Gradient Boosting Params:\", grid_gb.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71978dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(best_lr, \"models/life_exp_linear_regression.pkl\")\n",
    "joblib.dump(best_rf, \"models/life_exp_random_forest.pkl\")\n",
    "joblib.dump(best_gb, \"models/life_exp_gradient_boosting.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103367d3",
   "metadata": {},
   "source": [
    "# Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34100bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate a single model\n",
    "def evaluate(model, X_test, y_test, label):\n",
    "    preds = model.predict(X_test)\n",
    "    \n",
    "    mae = mean_absolute_error(y_test, preds)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "    r2 = r2_score(y_test, preds)\n",
    "    \n",
    "    return {\n",
    "        \"Model\": label,\n",
    "        \"MAE\": mae,\n",
    "        \"RMSE\": rmse,\n",
    "        \"R2 Score\": r2\n",
    "    }\n",
    "\n",
    "# Evaluate each model\n",
    "results = []\n",
    "results.append(evaluate(best_lr, X_test, y_test[target], \"Linear Regression\"))\n",
    "results.append(evaluate(best_rf, X_test, y_test[target], \"Random Forest\"))\n",
    "results.append(evaluate(best_gb, X_test, y_test[target], \"Gradient Boosting\"))\n",
    "\n",
    "# Convert to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "print(\"Evaluation Results for GDP Growth Rate:\")\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8427206f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison bar charts (MAE/RMSE/R²)\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.barplot(data=results_df, x=\"Model\", y=\"MAE\")\n",
    "plt.title(\"Model Comparison: MAE\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.barplot(data=results_df, x=\"Model\", y=\"RMSE\")\n",
    "plt.title(\"Model Comparison: RMSE\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.barplot(data=results_df, x=\"Model\", y=\"R2 Score\")\n",
    "plt.title(\"Model Comparison: R2 Score\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8f903b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models and their labels\n",
    "best_models = [\n",
    "    (\"Linear Regression\", best_lr),\n",
    "    (\"Random Forest\", best_rf),\n",
    "    (\"Gradient Boosting\", best_gb)\n",
    "]\n",
    "\n",
    "# Prediction vs Actual plot for the BEST models\n",
    "for model_name, model in best_models:\n",
    "    preds = model.predict(X_test)\n",
    "\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.scatter(y_test, preds, alpha=0.5)\n",
    "    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "    plt.xlabel(\"Actual Values\")\n",
    "    plt.ylabel(\"Predicted Values\")\n",
    "    plt.title(f\"Actual vs Predicted: {model_name}\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3399fd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models and their labels\n",
    "best_models = [\n",
    "    (\"Linear Regression\", best_lr),\n",
    "    (\"Random Forest\", best_rf),\n",
    "    (\"Gradient Boosting\", best_gb),\n",
    "]\n",
    "\n",
    "for model_name, model in best_models:\n",
    "    preds = model.predict(X_test).ravel()\n",
    "    y_test_series = y_test.squeeze().ravel()\n",
    "    residuals = y_test_series - preds\n",
    "\n",
    "    plt.figure(figsize=(8,4))\n",
    "    sns.histplot(residuals, kde=True)\n",
    "    plt.title(f\"Residual Distribution: {model_name}\")\n",
    "    plt.xlabel(\"Residual Error\")\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
